# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FDTzOXH0mY4Qcj_riM-52pIYbd2j3IxM

# Install necessary libraries
"""

!pip install contractions
!pip install wordcloud
!pip install xgboost
import contractions
import pandas as pd
import re
import matplotlib.pyplot as plt
import spacy
import string
import seaborn as sns
import unicodedata
from bs4 import BeautifulSoup
from google.colab import drive
drive.mount('/content/drive')
import unicodedata
nlp = spacy.load('en_core_web_sm')
from wordcloud import WordCloud
import nltk
nltk.download('wordnet')

from sklearn.model_selection import train_test_split
from keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report , f1_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score
from sklearn import metrics
import pickle as pk

"""# Loading dataset from google drive"""

df = pd.read_csv('/content/drive/MyDrive/nlp/IMDB Dataset.csv')

df.shape

df.info()

print(df)

"""# remove duplicate"""

# Check if there are aduplicated values in the data & drop it if found :
duplicated_features=df.duplicated().sum()
print("Number of duplicates ----->>> ",duplicated_features)
df = df.drop_duplicates()
duplicated_features=df.duplicated().sum()
print("Number of duplicates of cleaning it ----->>> ",duplicated_features)

df_backup = df.copy()
df.to_csv('/content/drive/MyDrive/nlp/IMDB Dataset_vf0.csv', sep='\t', encoding='utf-8', index=False, header=True)
df = df.drop('sentiment', axis=1)

"""# Cleaning dataset"""

def remove_emoji(text):
    emoji_pattern = re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)
df.review = df['review'].apply(remove_emoji)

def remove_html_tags(text):
    return BeautifulSoup(text, 'html.parser').get_text()
df.review = df['review'].apply(remove_html_tags)


def to_lowercase(text):
    return text.lower()
df.review = df['review'].apply(to_lowercase)


def standardize_accented_chars(text):
 return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')
df.review = df['review'].apply(standardize_accented_chars)


def expand_contractions(text):
    expanded_words = []
    for word in text.split():
       expanded_words.append(contractions.fix(word))
    return ' '.join(expanded_words)
df.review = df['review'].apply(expand_contractions)


def remove_url(text):
 return re.sub(r'https?:\S*', '', text)
df.review = df['review'].apply(remove_url)



def remove_mentions_and_tags(text):
    text = re.sub(r'@\S*', '', text)
    return re.sub(r'#\S*', '', text)

df.review = df['review'].apply(remove_mentions_and_tags)


def remove_special_characters(text):
    # define the pattern to keep
    pat = r'[^a-zA-z0-9.,!?/:;\"\'\s]'
    return re.sub(pat, '', text)
df.review = df['review'].apply(remove_special_characters)


def remove_numbers(text):
    pattern = r'[^a-zA-z.,!?/:;\"\'\s]'
    return re.sub(pattern, '', text)
df.review = df['review'].apply(remove_numbers)


def remove_punctuation(text):
    return ''.join([c for c in text if c not in string.punctuation])
df.review = df['review'].apply(remove_punctuation)


def data_processing(text):
  return re.sub('<br />', '', text)
df.review = df['review'].apply(data_processing)

df.review = df.review.replace(r'\s+', ' ', regex=True)

print(df)

df.to_csv('/content/drive/MyDrive/nlp/IMDB Dataset_vf1.csv', sep='\t', encoding='utf-8', index=False, header=True)

def remove_stopwords(text):
    filtered_sentence =[]
    doc=nlp(text)
    for token in doc:
        if token.is_stop == False:
          filtered_sentence.append(token.text)
    return ' ' .join(filtered_sentence)
df.review = df['review'].apply(remove_stopwords)

def lemmatize(text):
   doc = nlp(text)
   lemmatized_text = []
   for token in doc:
     lemmatized_text.append(token.lemma_)
   return ' '.join(lemmatized_text)
df['review'] = df.review.apply(lemmatize)

df.to_csv('/content/drive/MyDrive/nlp/IMDB Dataset_vf2.csv', sep='\t', encoding='utf-8', index=False, header=True)

print(df)



extracted_col = df_backup["sentiment"]
 # Add the extracted column to the second DataFrame
df2 = pd.concat([df, extracted_col.rename("sentiment")], axis=1)
df2.to_csv('/content/drive/MyDrive/nlp/IMDB Dataset_vf41.csv', sep='\t', encoding='utf-8', index=False, header=True)

plt.figure(figsize = (10,10))
wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(" ".join(df2[df2.sentiment == 'positive'].review))
plt.title("Positive Words")
plt.imshow(wc , interpolation = 'bilinear')

plt.figure(figsize = (10,10))
wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(" ".join(df2[df2.sentiment == 'negative'].review))
plt.title("Negative Words")
plt.imshow(wc , interpolation = 'bilinear')

max_words = df2['review'].apply(lambda x: len(x.split()))
plt.figure(figsize=(8, 6))
sns.histplot(max_words, bins=30)
plt.title('Distribution of Maximum Words in Sentences')
plt.xlabel('Number of Words')
plt.ylabel('Frequency')
plt.show()

df2['sentiment'] = df2['sentiment'].map({'positive': 1, 'negative': 0})

X = df2['review']
y = df2['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)
print("Train Data size:", len(X_train), len(y_train))
print("Test Data size", len(X_test), len(y_test))

tokenizer = Tokenizer()
tokenizer.fit_on_texts(X_train)
X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)

val_count=df2["sentiment"].value_counts()
plt.figure(figsize= (2,4))
sns.countplot(data = df2, x= 'sentiment')
plt.title(f'Sentiment Field Distribution\n{val_count.to_string(index=False, header=None)}')

max_len = 200  # Maximum words in each sequence.
batch_size=512
X_train = pad_sequences(X_train, maxlen=max_len)
X_test = pad_sequences(X_test, maxlen=max_len)
print(f"After padding: {X_train.shape}")
print(f"After padding:{X_test.shape}")

vocab_size=5000
embedding_dim = 100

model = LogisticRegression(C=1)
model.fit(X_train, y_train)

# Tahmin yapıp  doğruluğu ölçmek:
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

"""# Use TF - IDF"""

X_train, X_test, y_train, y_test = train_test_split(df2['review'], df2['sentiment'], test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

y_pred = model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
y_pred = (y_pred > 0.5).astype(int)
f1 = f1_score(y_test, y_pred)
print(f"F1 Score: {f1:.2f}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d',cmap='Blues')
plt.show()

model = SVC()
model.fit(X_train_tfidf, y_train)

y_pred = model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
y_pred = (y_pred > 0.5).astype(int)
f1 = f1_score(y_test, y_pred)
print(f"F1 Score: {f1:.2f}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d',cmap='Blues')
plt.show()

"""# save model"""

pk.dump(model,open('/content/drive/MyDrive/nlp/model.pkl','wb'))
pk.dump(vectorizer,open('/content/drive/MyDrive/nlp/scaler.pkl','wb'))

model = DecisionTreeClassifier()
model.fit(X_train_tfidf, y_train)
y_pred = model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
y_pred = (y_pred > 0.5).astype(int)
f1 = f1_score(y_test, y_pred)
print(f"F1 Score: {f1:.2f}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d',cmap='Blues')
plt.show()

model =  RandomForestClassifier()
model.fit(X_train_tfidf, y_train)


y_pred = model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
y_pred = (y_pred > 0.5).astype(int)
f1 = f1_score(y_test, y_pred)
print(f"F1 Score: {f1:.2f}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d',cmap='Blues')
plt.show()

model = GradientBoostingClassifier()
model.fit(X_train_tfidf, y_train)


y_pred = model.predict(X_test_tfidf)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
y_pred = (y_pred > 0.5).astype(int)
f1 = f1_score(y_test, y_pred)
print(f"F1 Score: {f1:.2f}")
print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d',cmap='Blues')
plt.show()

names = ['SVC', 'Logistic Regression', 'RandomForestClassifier', 'Decision Tree', 'GradientBoostingClassifier', 'XG Boost']
models = [SVC(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), GradientBoostingClassifier(), XGBClassifier()]
model_dict = dict(zip(models, names))

def model_fit(model, X_train_tfidf, y_train):
    model.fit(X_train_tfidf, y_train)
    train_score = roc_auc_score(y_train, model.predict(X_train_tfidf))
    test_score = roc_auc_score(y_test, model.predict(X_test_tfidf))
    return (train_score, test_score)

accuracy_list = []

def model_search_report(X_train_tfidf, y_train):
    # prepare scores
    train_scores = {}
    test_scores = {}
    for model, name in model_dict.items():
        train_score, test_score = model_fit(model, X_train_tfidf, y_train)
        train_scores[name] = train_score
        test_scores[name] = test_score

    # prepare reports
    report = pd.DataFrame()
    report['model'] = names
    report['train_score'] = train_scores.values()
    report['test_score'] = test_scores.values()

    print(report.sort_values(by='test_score'))

train_scores = {}
test_scores = {}
accuracy_list = []
for model, name in model_dict.items():
        train_score, test_score = model_fit(model, X_train_tfidf, y_train)
        train_scores[name] = train_score
        test_scores[name] = test_score


report = pd.DataFrame()
report['model'] = names
report['train_score'] = train_scores.values()
report['test_score'] = test_scores.values()
print(report.sort_values(by='test_score'))

models = [('Logistic Regression',LogisticRegression()),
          ('RandomForestClassifier',RandomForestClassifier()),
          ('Decision Tree',DecisionTreeClassifier()),
          ('Support Vector Classifier',SVC()),
          ('XG Boost',XGBClassifier())]


accuracy_list = []
for model in models:
    model[1].fit(X_train_tfidf, y_train)
    y_pred = model[1].predict(X_test_tfidf)
    accuracy_list.append(accuracy_score(y_test, y_pred))
plt.figure(figsize=(8, 4))
model_names = [x[0] for x in models]
y_pos = range(len(models))
#plt.bar(y_pos, accuracy_list, align='center', alpha=0.5)
plt.bar(y_pos, accuracy_list, color='pink')
plt.xticks(y_pos, [x[0] for x in models], rotation=7, fontsize= 10)
plt.ylabel('Accuracy')
plt.title('Comparision of Accuracies of Models',  fontweight=10,
          pad='2.0')


plt.show()

models = [('Logistic Regression',LogisticRegression()),
          ('RandomForestClassifier',RandomForestClassifier()),
          ('Decision Tree',DecisionTreeClassifier()),
          ("Gradient Boosting",GradientBoostingClassifier()),
          ('XG Boost',XGBClassifier())]
plt.plot([0, 1], [0, 1], 'k--', label='Random guess', linewidth=0.5)
for model in models:
    model[1].fit(X_train_tfidf, y_train)
    y_pred = model[1].predict_proba(X_test_tfidf)[:, 1]
    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)
    auc = round(metrics.roc_auc_score(y_test, y_pred), 4)
    model_names = [x[0] for x in models]
    plt.plot(fpr,tpr,label= model[0]+str(auc), linewidth=0.5)
    _ = plt.xlabel('False Positive Rate')
    _ = plt.ylabel('True Positive Rate')
    plt.legend()